

MODEL:
  LOAD_CHECKPOINT: /mnt/gpid07/users/adria.caelles/output_dir/T02_GCNN-TRAINING/checkpoints/T02_GCNN-TRAINING_epoch_6.pth
  RUNTIME_CONFIG:
    # Epoch at which the actions will be done
    FreezeDeepLabV3Plus: 0
    FreezeRVOSEncoder: -1
    UnfreezeRVOSEncoder: -1
    UsePreviousInferenceMask: 7

OAGCNN:
  MESSAGE_PASSING_STEPS: 3
  USE_TEMPORAL_FEATURES: True
  BACKPROPAGATE_FEATURES: True
  USE_PREVIOUS_INFERENCE_MASK: True
  # Whether to backpropagate gradients through the predicted mask or use just the mask itself (data)
  # Keeping gradient will increase memory usage
  BACKPROPAGATE_PREDICTED_MASKS: True
  NUM_CLASSES: 1
  # MaskedNLLLoss, MaskedBCELoss, SoftIoULoss
  LOSS_FUNCTION: SoftIoULoss
  
  ARCH:
    FEATURE_EXTRACTOR: DeepLabV3Plus
    
    GRAPH:
      MASK_ENCODING_MODULE: MaskEncoderOneStage
      # GCNNSimple, GCNNConvBlocks, GRUGCNN
      GCNN_MODULE: GRUGCNN
      READ_OUT: ReadOutSimple

DeepLabV3PlusFeatExtract:
  BACKBONE_NAME: resnet50
  OUTPUT_STRIDE: 16
  OUT_CHANNELS: 8
  LOAD_PRETRAINED: True

MaskEncoderOneStage:
  OUT_CHANNELS: 16

DATA:
  NUM_WORKERS: 5
  SHUFFLE: True
  DROP_LAST: True
  BATCH_SIZE: 4
  VAL_BATCH_SIZE: 1
  CLIP_LENGTH: 5
  MAX_NUM_OBJ: 10
  IMAGE_SIZE: (256, 448)
  AUGMENTATION: True

AUG_TRANSFORMS:
  ROTATION: 10
  TRANSLATION: 0.1
  SHEAR: 0.1
  ZOOM: 0.7

SOLVER:
  OPTIMIZER: Adam
  LR: 0.001
  WEIGHT_DECAY: 0.0001
  NUM_EPOCHS: 20
  CHECKPOINTER:
    SAVE_ALWAYS: True
    PATIENCE: 10
    PATIENCE_DELTA: 0.
  USE_SCHEDULER: True
  LR_SCHEDULER:
    NAME: "MultiStepLR"
    STEPS: [14, 17]
    STEP_SIZE: 0.1
  EVALUATION_METRIC: "loss"
  

DATASETS:
  TRAIN: YouTubeVOS
  TRAIN_SPLIT: train
  VAL: YouTubeVOS
  VAL_SPLIT: val
  TEST: YouTubeVOS
  TEST_SPLIT: test


GENERAL_CONFIG:
  TRAIN_NAME: T01.06_MASK-ENCODER_TEMPORAL_FREEZE-DEEPLAB
  PRINT_EVERY: 5
  USE_GPU: True